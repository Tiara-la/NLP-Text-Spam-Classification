# -*- coding: utf-8 -*-
"""Proyek Akhir NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19q_ZT3BszuuXZHNOZc549kF8m5KRTJGI

Nama : Tiara Lailatul Nikmah  
User Name : Tiara Laila  
Email : tiaralaila21@gmail.com  
No Telepon : 089635924667  
Asal Kota : Juwana,Pati
"""

import pandas as pd
df = pd.read_csv('SPAM text message.csv')

df.head()

# melakukan proses one-hot-encoding karena "label" berupa data kategorikal
category = pd.get_dummies(df.Category)
df_baru = pd.concat([df, category], axis=1)

df_baru.info()

# mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values
pesan = df_baru['Message'].values
label = df_baru[['ham', 'spam']].values
df_baru = df_baru.drop(columns='Category')
df_baru

# bagi data untuk training dan data untuk testing
from sklearn.model_selection import train_test_split
pesan_latih, pesan_test, label_latih, label_test = train_test_split(pesan, label, test_size=0.2)

#  ubah setiap kata pada dataset ke dalam bilangan numerik dengan fungsi Tokenizer
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(pesan_latih) 
tokenizer.fit_on_texts(pesan_test)


# mengonversi setiap sampel menjadi sequence 
sekuens_latih = tokenizer.texts_to_sequences(pesan_latih)
sekuens_test = tokenizer.texts_to_sequences(pesan_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

#  menggunakan layer Embedding dengan dimensi embedding sebesar 16
# dimensi dari input sebesar nilai num_words pada objek tokenizer

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(256, activation='relu'),              # hiden layer 1
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(128, activation='relu'),               # hiden layer 2
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(2, activation='softmax')
])


# panggil fungsi compile dan tentukan optimizer serta loss function
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.summary()

# fungsi callback untuk menghentikan epoch apabila akurasi sudah mencapai 98%
class toCallback(tf.keras.callbacks.Callback): 
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.98 and logs.get('accuracy')==1.00):
      print("Proses Training Berhenti, Tingkat Akurasi Sudah Lebih Dari 98%")
      self.model.stop_training = True

callbacks= toCallback()

# mulai melatih model dengan memanggil fungsi fit()
num_epochs = 30
latih = model.fit(padded_latih, label_latih, epochs=num_epochs, batch_size=256,
                  validation_data=(padded_test, label_test), verbose=2, 
                  callbacks=[callbacks]) # memanggil fungsi callback

# membuat grafik akurasi data training dan validasi
import matplotlib.pyplot as plt

akurasi = latih.history['accuracy']
val_akurasi = latih.history['val_accuracy']
loss = latih.history['loss']
val_loss = latih.history['val_loss']

epoch_range = range(len(akurasi))

plt.plot(epoch_range, akurasi, label='Training accuracy')
plt.plot(epoch_range, val_akurasi, label='Validation accuracy')
plt.title('Grafik akurasi training dan validasi')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(loc=0)
plt.figure()
plt.show()

plt.plot(epoch_range, loss, label='Training loss')
plt.plot(epoch_range, val_loss, label='Validation loss')
plt.title('Grafik error training dan validasi')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(loc=0)
plt.figure()
plt.show()